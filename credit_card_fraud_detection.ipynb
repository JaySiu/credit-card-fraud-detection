{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-099fb22928fe>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-099fb22928fe>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    import pyspark-csv\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import dbutils\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark-csv\n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SECRET_ACCESS_KEY=\"aWlGdedlHIR5asFQE2vAF5l3LPdfoYL5SMMgejkk\"\n",
    "# ACCESS_KEY_ID=\"AKIAI5AUGUGKHT2VCQ5Q\"\n",
    "# # ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "# # AWS_BUCKET_NAME = \"creditfrauddata\"\n",
    "\n",
    "\n",
    "# Set up AWS S3 access credentials\n",
    "ACCESS_KEY = \"AKIAI5AUGUGKHT2VCQ5Q\"\n",
    "SECRET_KEY = \"aWlGdedlHIR5asFQE2vAF5l3LPdfoYL5SMMgejkk\"\n",
    "ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "AWS_BUCKET_NAME = \"creditfrauddata\"\n",
    "\n",
    "# mounts_list = [\n",
    "# {'bucket':'creditfrauddata/', 'mount_folder':'/mnt/creditfrauddata'}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert csv file to Spark DataFrame (Databricks version)\n",
    "def loadDataFrame(fileName, fileSchema):\n",
    "    return (sc.read.format(\"csv\")\n",
    "            .schema(fileSchema)\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"mode\", \"DROPMALFORMED\")\n",
    "            .csv(\"s3a://%s:%s@%s/%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME, fileName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "paymentSchema = StructType([\n",
    "    StructField(\"step\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"amount\", FloatType(), True),\n",
    "    StructField(\"nameOrig\", StringType(), True),\n",
    "    StructField(\"oldbalanceOrg\", FloatType(), True),\n",
    "    StructField(\"newbalanceOrig\", FloatType(), True),\n",
    "    StructField(\"nameDest\", StringType(), True),\n",
    "    StructField(\"oldbalanceDest\", FloatType(), True),\n",
    "    StructField(\"newbalanceDest\", FloatType(), True),\n",
    "    StructField(\"isFraud\", IntegerType(), True),\n",
    "    StructField(\"isFlaggedFraud\", IntegerType(), True)])\n",
    "\n",
    "# movieSchema = StructType([\n",
    "#     StructField(\"movieId\", IntegerType(), True),\n",
    "#     StructField(\"title\", StringType(), True),\n",
    "#     StructField(\"genres\", StringType(), True)])\n",
    "\n",
    "# smallMovieRatingsDF = loadDataFrame(\"ratings-small.csv\", movieRatingSchema).cache()\n",
    "# paymentDF = loadDataFrame(\"PS_20174392719_1491204439457_log.csv\", paymentSchema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"', u'0,-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62,\"0\"', u'0,1.19185711131486,0.26615071205963,0.16648011335321,0.448154078460911,0.0600176492822243,-0.0823608088155687,-0.0788029833323113,0.0851016549148104,-0.255425128109186,-0.166974414004614,1.61272666105479,1.06523531137287,0.48909501589608,-0.143772296441519,0.635558093258208,0.463917041022171,-0.114804663102346,-0.183361270123994,-0.145783041325259,-0.0690831352230203,-0.225775248033138,-0.638671952771851,0.101288021253234,-0.339846475529127,0.167170404418143,0.125894532368176,-0.00898309914322813,0.0147241691924927,2.69,\"0\"', u'1,-1.35835406159823,-1.34016307473609,1.77320934263119,0.379779593034328,-0.503198133318193,1.80049938079263,0.791460956450422,0.247675786588991,-1.51465432260583,0.207642865216696,0.624501459424895,0.066083685268831,0.717292731410831,-0.165945922763554,2.34586494901581,-2.89008319444231,1.10996937869599,-0.121359313195888,-2.26185709530414,0.524979725224404,0.247998153469754,0.771679401917229,0.909412262347719,-0.689280956490685,-0.327641833735251,-0.139096571514147,-0.0553527940384261,-0.0597518405929204,378.66,\"0\"', u'1,-0.966271711572087,-0.185226008082898,1.79299333957872,-0.863291275036453,-0.0103088796030823,1.24720316752486,0.23760893977178,0.377435874652262,-1.38702406270197,-0.0549519224713749,-0.226487263835401,0.178228225877303,0.507756869957169,-0.28792374549456,-0.631418117709045,-1.0596472454325,-0.684092786345479,1.96577500349538,-1.2326219700892,-0.208037781160366,-0.108300452035545,0.00527359678253453,-0.190320518742841,-1.17557533186321,0.647376034602038,-0.221928844458407,0.0627228487293033,0.0614576285006353,123.5,\"0\"']\n"
     ]
    }
   ],
   "source": [
    "# rdd = sc.hadoopFile('s3n://creditfrauddata/PS_20174392719_1491204439457_log.csv', conf = {\n",
    "#   'fs.s3n.awsAccessKeyId': ACCESS_KEY,\n",
    "#   'fs.s3n.awsSecretAccessKey': SECRET_KEY\n",
    "# })\n",
    "\n",
    "fileName = 'PS_20174392719_1491204439457_log.csv'\n",
    "fileName2 = 'creditcard.csv'\n",
    "rdd = sc.textFile(\"s3n://%s:%s@%s/%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME, fileName2))\n",
    "print(rdd.take(5))\n",
    "\n",
    "# stuff = sqlContext.read.format('com.databricks.spark.csv').option('delimiter', '\\t').load(\"s3n://%s:%s@%s/%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME, fileName))\n",
    "# print(stuff.take(1))\n",
    "\n",
    "# sc.textFile(\"s3n://%s:%s@%s/%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME, fileName)) \\\n",
    "#     .map(lambda line: line.split(\",\")) \\\n",
    "#     .filter(lambda line: len(line)>1) \\\n",
    "#     .map(lambda line: (line[0],line[1])) \\\n",
    "#     .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
